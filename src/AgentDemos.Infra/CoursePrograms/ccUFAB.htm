<html>

<head>
    <title>Data Engineering with Microsoft Fabric</title>
    <meta name="NumberOfDays" content="5" />
</head>

<body>
    <h2>
        Learning Goals
    </h2>
    <p>
        Microsoft Fabric is an all-in-one analytics solution for enterprises that covers everything from data movement
        to data science, real-time analytics, and business intelligence.
        It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in
        one place.
        In this 5-day course, you will learn about and experience the major parts of Microsoft Fabric.
    </p>
    <h2>
        Target audience
    </h2>
    <p>
        This course is targeted to data engineers and BI professionals who want to build and use lakehouses and data
        warehouses
        using Microsoft Fabric.
    </p>
    <h2>
        Course Outline
    </h2>

    <h4>Introduction into Microsoft Fabric</h4>
    <p>
        The chapter introduces the data lake approach. It also provides a high-level overview of the building blocks
        of Microsoft Fabric and how to get started. The Data Mesh architecture is discussed and compared with Microsoft
        Fabric.
    </p>
    <ul>
        <li>What is Microsoft Fabric?</li>
        <li>From traditional data warehousing to data lakes</li>
        <li>Data Mesh Architecture</li>
        <li>Working with Task Flow</li>
        <li>Microsoft Fabric Licensing</li>
        <li>Monitor Microsoft Fabric</li>
        <li>Domains and Workspaces in Microsoft Fabric</li>
        <li>LAB: Getting started with Microsoft Fabric</li>
    </ul>

    <h4>Introduction to Data Lakes</h4>
    <p>Microsoft Fabric is built on the idea of replacing a traditional data warehouse with a data lake. This module
        explains why and how the relational data warehouse could be replaced by a file-based data lake.</p>
    <ul>
        <li>From Data Warehouse to Data Lake</li>
        <li>Volume, velocity and variety problems</li>
        <li>From Data Lake to Lakehouse</li>
    </ul>

    <h4>Microsoft OneLake</h4>
    <p>Microsoft OneLake is the OneDrive equivalent for business data: A place to host files (data lake or delta lake)
        and tables.</p>
    <ul>
        <li>What is OneLake?</li>
        <li>Creating Workspaces</li>
        <li>Working with Domains</li>
        <li>Workspaces and Source Control: Azure DevOps and Github integration</li>
    </ul>

    <h4>Storing Data in OneLake</h4>
    <p>
        OneLake provides a single, unified, logical data lake for your whole organization.
        Like OneDrive, OneLake comes automatically with every Microsoft Fabric tenant and is designed to be the single
        place for all your analytics data.
    </p>
    <ul>
        <li>Creating a LakeHouse</li>
        <li>Manually loading data in Lakehouse        </li>
        <li>The Lakehouse SQL Analytics Endpoint        </li>
        <li>The Default (Power BI) Semantics Model        </li>
        <li>Working with Shortcuts        </li>
        <li>Connecting External Applications with Microsoft OneLake</li>
        <li>LAB: Setting up Lakehouses in OneLake</li>
    </ul>


    <h4>Getting started with Data Factory</h4>
    <p>
        Data Factory allows you to ingest, prepare and transform data from a rich set of data sources like databases,
        files, cloud data sources,...
        This chapter illustrates how to use Activities to build pipelines that ingest data in a Lakehouse.
    </p>
    <ul>
        <li>What is Data Factory ?</li>
        <li>Creating Data Pipelines        </li>
        <li>The Copy Data Activity        </li>
        <li>Executing and Monitoring Data Pipelines        </li>
        <li>LAB: Ingesting data using Pipelines</li>
    </ul>

    <h4>Authoring advanced Pipelines</h4>
    <p>
        This module dives deeper into the process of building an Fabric pipeline.
        The module mainly focusses on how to work with expressions, variables and parameters to make dynamic pipelines.
    </p>
    <ul>
        <li>Working with Expressions</li>
        <li>Variables and Parameters</li>
        <li>Using Looping and Conditional Logic in pipelines</li>
        <li>Debugging a pipeline</li>
        <li>LAB: Authoring and debugging advanced Pipeline</li>
    </ul>

    <h4>Ingest and Transform data using Dataflow Gen2</h4>
    <p>
        With Dataflows you can visually design data transformations without the need to learn yet another tool or
        language.
        Dataflows in Microsoft Fabric are based on Power Query Online.
    </p>
    <ul>
        <li>Creating Queries to load data</li>
        <li>Applying Transformations</li>
        <li>Appending and Merging Queries</li>
        <li>Query Folding</li>
        <li>Using Dataflows inside a Pipeline</li>
        <li>Managing connections</li>
        <li>LAB: Ingesting and transforming using Dataflows</li>
    </ul>

    <h4>Data Engineering with Spark</h4>
    <p>
        Data engineering is the process of designing and building systems that let people collect and analyze raw data
        from multiple sources and formats.
        Using popular languages such as Python, SQL and R data can be loaded, transformed and analyzed via interactive
        notebooks.
    </p>
    <ul>
        <li>Introducing Apache Spark</li>
        <li>Creating Environments or Apache Spark clusters</li>
        <li>Working with Notebooks in Fabric</li>
        <li>Magic commands</li>
        <li>Visual Studio Code integration</li>
        <li>Scheduling Notebooks</li>
        <li>Microsoft Fabric decision guide: Copy activity, Dataflow or Spark</li>
        <li>Using Python Notebooks</li>
        <li>LAB: Getting started with Notebooks in Microsoft Fabric</li>
    </ul>

    <h4>Data wrangling using PySpark and Spark SQL</h4>
    <p>
        PySpark and Spark SQL allow users to perform complex data processing tasks with few lines of code using
        Notebooks.
    </p>
    <ul>
        <li>The SparkSession, SparkContext and SQLContext objects</li>
        <li>Reading and writing data using DataFrames</li>
        <li>Data Cleansing using PySpark</li>
        <li>Grouping and aggregating data in PySpark</li>
        <li>Joining DataFrames</li>
        <li>Using Spark SQL to select and manipulate data</li>
        <li>Visualizing data using Notebooks and DataFrames</li>
        <li>LAB: Data wrangling using PySpark and Spark SQL</li>
    </ul>

    <h4>Working with Delta Tables</h4>
    <p>
        Delta Lake is an optimized storage layer that provides the foundation for storing data and tables in a Fabric
        lakehouse.
        Learn how to create, query and optimize Delta Tables in a Microsoft Fabric.
    </p>
    <ul>
        <li>what is a Delta Lake</li>
        <li>Working with Delta Tables</li>
        <li>Managing Schema change</li>
        <li>Version and Optimize Delta Tables</li>
        <li>LAB: Working with Delta Tables</li>
    </ul>

    <h4>Building a Fabric Data Warehouse</h4>
    <p>
        A Synapse Data Warehouse is a database that stores data in OneLake and provides a medium to interact with the
        database using SQL commands.
    </p>
    <ul>
        <li>The SQL analytics endpoint of the Lakehouse</li>
        <li>Creating tables in a Synapse Data Warehouse</li>
        <li>Ingesting data using pipelines</li>
        <li>Ingesting data using T-SQL</li>
        <li>Querying the Warehouse</li>
        <li>The Default Power BI semantic model</li>
        <li>LAB: Creating and using a Warehouse</li>
    </ul>

    <h4>Fabric SQL Databases</h4>
    <p>Sometimes the restrictions on a Fabric Data Warehouse make it difficult to use for applications that are closer
        to the operational side. With Fabric SQL Databases, an operational database becomes available, with constraints,
        indexes, and many more features that SQL Server users might be used to.
    </p>
    <ul>
        <li>What is Fabric SQL Database</li>
        <li>Connecting clients to the database</li>
        <li>Controlling security</li>
        <li>Disaster recovery</li>
        <li>Fabric SQL Database versus Fabric Warehouse</li>
    </ul>

    <h4>Real-Time Analytics in Fabric</h4>
    <p>
        Real-Time Analytics is a fully managed big data analytics platform optimized for streaming, time-series data.
        It contains a dedicated query language and engine with for searching structured, semi-structured, and
        unstructured data in close to real-time.
    </p>
    <ul>
        <li>Creating a KQL database</li>
        <li>Ingesting data into tables</li>
        <li>Query data using KQL</li>
        <li>Create and manage EventStreams</li>
        <li>LAB: Working with Real-Time Analytics</li>
    </ul>


    <h4>Reporting in Fabric</h4>
    <p>
        Power BI transforms your company's data into rich visuals for you to monitor your business and get answers
        quickly.
        Learn how to connect to your data stored in Microsoft Fabric using Power BI.
    </p>
    <ul>
        <li>Creating Power BI Reports</li>
        <li>DirectQuery vs Import with Microsoft OneLake</li>
        <li>Using and configuring Direct Lake mode</li>
        <li>LAB: Creating Power BI Reports</li>
    </ul>


    <h4>Data Activator</h4>
    <p>
        Data Activator in Microsoft Fabric takes action based on what's happening in your data.
        Learn how to setup conditions against your data and trigger actions like run a Power Automate Flow when the
        conditions are met.
    </p>
    <ul>
        <li>Creating and using Reflexes</li>
        <li>Defining Triggers, Conditions and Actions</li>
        <li>Getting data from Reports or EventStreams</li>
        <li>LAB: Use Data Activator in Fabric</li>
    </ul>

</body>

</html>