<html xmlns:mso="urn:schemas-microsoft-com:office:office" xmlns:msdt="uuid:C2F41010-65B3-11d1-A29F-00AA00C14882">

<head>
  <title>Developing AI-Powered Apps with C# and Azure AI</title>
  <meta name="NumberOfDays" content="3" />
  <!--[if gte mso 9]><xml>
<mso:CustomDocumentProperties>
<mso:ContentTypeId msdt:dt="string">0x0101009C33340F38E14D1EABEAC83093A8F17200D855D825770DC448ADBFD1832C0E65A9</mso:ContentTypeId>
</mso:CustomDocumentProperties>
</xml><![endif]-->
</head>

<body>
  <h2>Learning Goals</h2>
  <p>

    In this course, you will learn to seamlessly integrate pre-built AI services and Large Language Models such as ChatGPT and Phi into your .NET development projects.
    The course will teach you how to use your own data with Large Language Models using Azure AI Search.
    Furthermore, you will gain hands-on experience with AI libraries such as Semantic Kernel.
    This course will equip you with the skills to integrate advanced AI capabilities into your software solutions without needing to be a data scientist.
  </p>
  <h2>Target Audience</h2>
  <p>
    This course targets professional C# developers that want to get started with the Microsoft AI platform. Participants of
    this course need to have a decent understanding of C# and preferably some experience with Microsoft Azure.
    This is not a course for data scientists who want to build their own AI models or understand how existing AI models work.
  </p>
  <h2>Course Outline</h2>

  <h4>What is Artificial Intelligence?</h4>
  <p>
    In this chapter you will get a short overview about what AI is exactly, and what we can do with it.
  </p>
  <ul>
    <li>Definitions of Artificial Intelligence</li>
    <li>Machine Learning Basics</li>
    <li>Domains of Artificial Intelligence</li>
    <li>History, Current State and Future</li>
  </ul>

  <h4>Ready-to-Use AI Models with Azure AI Services</h4>
  <p>
    Azure AI services provides a comprehensive suite of out-of-the-box and customizable AI tools, APIs, and pre-trained models that
     detect sentiment, recognize speakers, understand pictures and many more.
  </p>
  <ul>
    <li>Azure AI Services Overview</li>
    <li>Azure AI Language</li>
    <li>Azure AI Vision</li>
    <li>Azure AI Speech</li>
    <li>Azure AI Document Intelligence</li>
    <li>LAB: Creating an AI Powered Insurance Claim Processor</li>
  </ul>

  <h4>Azure OpenAI and Large Language Model Fundamentals</h4>
  <p>
    This module introduces Azure OpenAI and the GPT family of Large Language Models (LLMs). You'll 
    learn about available LLM models, how to configure and use them in the Azure Portal, and the Transformer 
    architecture behind models like GPT-4o. The latest GPT models offer Function Calling, enabling connections 
    to external tools, services, or code, allowing the creation of AI-powered Copilots. Additionally, you'll discover 
    how Azure OpenAI provides a secure way to use LLMs without exposing your company's private data.
  </p>
  <ul>
    <li>Introducing OpenAI and Large Language Models</li>
    <li>The Transformer Model</li>
    <li>What is Azure OpenAI?</li>
    <li>Configuring Deployments</li>
    <li>Understanding Tokens</li>
    <li>LLM Pricing</li>
    <li>Azure OpenAI Chat Completions API</li>
    <li>Role Management: System, User and Assistant</li>
    <li>Azure OpenAI SDK</li>
    <li>Extending LLM capabilities with Function Calling</li>
    <li>LAB: Deploying and Using Azure OpenAI</li>
  </ul>

  <h4>Orchestrating AI Models using Semantic Kernel</h4>
  <p>
    Semantic Kernel is an open-source SDK backed by Microsoft that seamlessly integrates Large Language Models 
    such as OpenAI and Azure OpenAI with programming languages like C#. 
    It allows users to use natural language input within Large Language Models to seamlessly invoke and interact 
    with your custom code.
  </p>
  <ul>
    <li>An Introduction to Semantic Kernel</li>
    <li>Integrating LLMs in your applications</li>
    <li>Keeping track of Token Usage</li>
    <li>Enable AI Models to execute code using Plugins</li>
    <li>Control AI Models with Filters</li>
    <li>Best practices for dependency injection in managing AI services</li>
    <li>Observable AI Apps with OpenTelemetry</li>
    <li>LAB: Create a Natural Language to SQL Translation Copilot</li>
  </ul>

  <h4>Retrieving Semantically Related Data with Vector Search</h4>
  <p>
    Vector search is a powerful technique that allows you to retrieve semantically 
    related data from large datasets such as company documents or databases. 
    This chapter will teach you how vector search works and how it enables you to
    find relevant information without depending on exact keyword based search terms
    or language of the information in the dataset.
  </p>
  <ul>
    <li>Capture Semantic Meaning with Embeddings</li>
    <li>Vector Search</li>
    <li>Vector Search Design Considerations</li>
  </ul>

  <h4>Using your own data in a LLM with Azure AI Search</h4>
  <p>
    Azure AI Search facilitates the adoption of the Retrieval Augmented Generation (RAG) design pattern. 
    This methodology involves retrieving pertinent information from a data source and using it to increase the 
    knowledge of generative AI models.This combination of retrieval and generation sets a new standard 
    for AI-driven search solutions.</p>
  <ul>
    <li>What is Azure AI Search?</li>
    <li>Retrieval Augmented Generation</li>
    <li>Creating an Index on your Own Data</li>
    <li>AI Enrichment with your own Data</li>
    <li>Using the Azure OpenAI SDK</li>
    <li>Privacy Concerns</li>
    <li>Fine-tuning vs RAG</li>
    <li>LAB: Chat with Azure OpenAI models using your own data</li>
  </ul>

  <h4>Prompt Engineering and Design Patterns</h4>
  <p>
    In this chapter, you'll explore advanced techniques allowing you to control the 
    model's output, transforming generic responses into precise, valuable results. Additionally 
    the chapter covers emerging design patterns in the field of Gen AI app development that help 
    you increase quality of model responses and reduce costs.
  </p>
  <ul>
    <li>What is Prompt Engineering?</li>
    <li>Few-Shot Prompting</li>
    <li>Structured Query Generation</li>
    <li>Verifying Model responses with Hallucination Detection</li>
    <li>Saving costs with Semantic Caching</li>
  </ul>

  <h4>Deploying AI Models on Azure AI Foundry</h4>
  <p>
    The cost and quality of your AI-powered app depend largely on 
    your choice of AI model and how you deploy it. Learn about the 
    available model catalog, featuring state-of-the-art Azure OpenAI 
    models and open-source models from Hugging Face, Meta, Google, 
    Microsoft, Mistral, and many more. 
  </p>
  <ul>
    <li>Model Catalog Overview</li>
    <li>Model Benchmarks</li>
    <li>Selecting the Best Deployment Mode</li>
    <li>LAB: Deploying an Open Source AI Model on Azure AI Foundry</li>
  </ul>

  <h4>Working with Open-Source Language Models</h4>
  <p>
    This chapter empowers you to bring powerful AI capabilities to end-user 
    environments like mobile devices, personal computers and browsers, enhancing scalability, 
    costs and performance. Additionally you will learn how to deploy and host your own open-source
    Language Models in the form of an API that you have full control over.
  </p>
  <ul>
    <li>The Phi-3 Family of Small Language Models</li>
    <li>Deploying AI Models on Mobile and Edge Devices with ONNX Runtime</li>
    <li>Hosting and Deploying Language Models on-prem and in the cloud with Ollama</li>
  </ul>

  <h4>Testing and Moderating AI Models</h4>
  <p>
    How can you ensure an LLM provides relevant and coherent
    answers to users' questions using the correct info? How do you prevent an LLM from responding
    inappropriately? Discover the answers to these questions and more by exploring
    evaluation metrics in Azure AI Foundry and the Azure AI Content Safety
    Service.
  </p>
  <ul>
    <li>Ensuring Coherent and Relevant LLM Responses</li>
    <li>Utilizing Correct Information in AI Answers</li>
    <li>Preventing Inappropriate LLM Responses</li>
    <li>Leveraging Azure AI Content Safety Service</li>
    <li>Enhancing AI Performance and Safety</li>
    <li>LAB: Evaluating the Performance of a RAG App</li>
  </ul>

  <h4>Building on the Microsoft Copilot Ecosystem</h4>
  <p>
    While building a complete AI-powered application from scratch can be 
    beneficial, it is sometimes not the most efficient approach. In this chapter, 
    you will learn the basics of extending the capabilities and knowledge of 
    Copilot for Microsoft 365, allowing you to enhance its functionality and leveraging its robust and secure infrastructure and 
    UI.
  </p>
  <ul>
    <li>Overview of Copilot for Microsoft 365 Extensibility Options</li>
    <li>Overview of Copilot Studio</li>
    <li>Extending Copilot's knowledge with Graph Connectors</li>
    <li>Allowing Microsoft Copilot to call REST API's</li>
    <li>Expanding Copilot Capabilities via Teams Message Extensions</li>
  </ul>

</body>

</html>
