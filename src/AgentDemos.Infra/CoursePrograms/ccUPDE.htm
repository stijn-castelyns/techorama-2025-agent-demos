<head>
    <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
    <title>Python for Data Engineering: From Syntax to Solutions</title>
    <meta name="NumberOfDays" content="3">
</head>

<body>
    <h2>Learning Goals</h2>

    <p>
        Python plays a crucial role in data engineering, data science and AI development due to its versatility,
        extensive libraries such as Pandas and
        PySpark,
        and its ability to handle large-scale data processing, making it an indispensable tool for extracting insights
        and building data pipelines.
        In this course, participants will gain a solid understanding of Python. </p>
    <p>
        They will acquire the necessary skills and knowledge to utilize Python effectively,
        from basic syntax to implementing real-world solutions. During the course participants will get hands-on
        experience with Pandas, PySpark, Delta Lake...
    </p>

    <h2>Target Audience</h2>
    <p>
        This course is targeted at data engineers, data scientists and AI developers with no or little experience with
        Python. Familiarity with programming in general might come in handy.
    </p>

    <h2>Course Outline</h2>

    <h4>Getting Started with Python</h4>
    <p>
        Python is a high-level, interpreted, interactive and object-oriented scripting language. This chapter introduces
        the history of Python and
        how to install Python and run your first lines of Python Code. There are quite some editors available for
        writing Python code but this course
        focusses on using Visual Studio Code as a code editor for Python.
    </p>
    <ul>
        <li>Introduction to Python</li>
        <li>Installing Python</li>
        <li>Executing Python Code from the Command Shell</li>
        <li>Python and Visual Studio Code</li>
        <li>Working with packages in Python</li>
        <li>Working with Virtual Environments in Python</li>
        <li>Interactive development in Jupyter notebooks</li>
        <li>LAB: Installing Python and executing code</li>
    </ul>

    <h4>Basic Language Constructs in Python</h4>
    <p>
        To build code that remains readable and maintainable it is important to be able to break up code in reusable
        components such as functions and classes.
    </p>
    <ul>
        <li>Introduction to writing Python code</li>
        <li>Declaring and Using Variables</li>
        <li>Data Types in Python</li>
        <li>Working with Lists, Tuples, Sequences and Dictionaries</li>
        <li>Basic Programming Constructs in Python</li>
        <li>Declaring and executing Functions</li>
        <li>LAB: Writing basic Python code</li>
    </ul>

    <h4>Working with Classes and Objects</h4>
    <p>
        Python classes provide all the standard features of Object Oriented Programming. Classes can
        inherit from other base classes, have Constructors for the initialization of objects...
    </p>
    <ul>
        <li>Introduction to Object-Oriented Programming</li>
        <li>Defining and instantiating Classes in Python</li>
        <li>Working with Constructors</li>
        <li>Instance and Class Variables</li>
        <li>Inheritance in Python</li>
        <li>Working with Access Modifiers</li>
        <li>LAB: Working with classes and objects</li>
    </ul>

    <h4>Using and Creating Modules</h4>
    <p>
        Modules in Python are reusable code libraries and Python ships with quite a large amount of build-in Modules.
        Learn how to create and import Modules.
    </p>
    <ul>
        <li>Introduction to Modules</li>
        <li>Importing Modules</li>
        <li>Creating Modules</li>
        <li>LAB: Using and creating Modules</li>
    </ul>

    <h4>Data Processing and Cleansing using Pandas</h4>
    <p>
        Pandas is a Python library which makes loading and transforming data a lot easier. As long as all your data fits
        in memory, Pandas is your friend.
    </p>
    <ul>
        <li>What is Pandas</li>
        <li>Introducing Pandas Data Structures</li>
        <li>Reading data with Pandas</li>
        <li>Indexing in a DataFrame</li>
        <li>Creating and deleting columns</li>
        <li>Filtering and Replacing data</li>
        <li>Sorting and Ranking data</li>
        <li>Grouping and aggregating data</li>
        <li>Regular Expressions</li>
        <li>LAB: Working with Pandas</li>
    </ul>

    <h4>From Python and Pandas to Apache Spark</h4>
    <p>
        With Pandas you typically run code on a single machine. This means that as your data volumes become bigger and
        bigger, you will be hitting memory and cpu constraints.
        PySpark is a Spark library written in Python to run Python applications using Apache Spark.
        Apache Spark is an analytical processing engine for large scale powerful distributed data processing and machine
        learning applications.
        In Azure it is available in Azure Synapse Analytics and Azure Databricks.
    </p>
    <ul>
        <li>Introducing Apache Spark</li>
        <li>The SparkSession, SparkContext and SQLContext objects</li>
        <li>An introduction to Resilient Distributed Datasets (RDD)</li>
        <li>Convert a Pandas DataFrame to/from a PySpark DataFrame</li>
        <li>Working with Parquet files</li>
        <li>Working with DataFrames in PySpark</li>
        <li>Data Cleansing using PySpark</li>
        <li>Grouping and aggregating data in PySpark</li>
        <li>Joining DataFrames</li>
        <li>Using SQL to select and manipulate data</li>
        <li>LAB: Data manipulation in Apache Spark</li>
    </ul>

    <h4>Building a Lakehouse using Delta Lake</h4>
    <p>
        Parquet is a very popular data format in the Big Data community, since it can store large volumes of data in a
        compact and easy to query way. But it doesn't allow to modify your data.
        So, a variant has been developed by Databricks, called Delta. This module explains this Delta format and shows
        how to use Delta format in Spark.
    </p>
    <ul>
        <li>What Is a Lakehouse?</li>
        <li>Introduction to Delta Lake</li>
        <li>Creating tables</li>
        <li>Partitioning data in tables</li>
        <li>Reading table data</li>
        <li>Query older snapshots of a table (Time Travel)</li>
        <li>Insert, Update, Delete and Merge table data</li>
        <li>Retrieving table metadata</li>
        <li>Altering table metadata</li>
        <li>Configuring Change Data Feed</li>
        <li>LAB: Modifying data using Delta Lake</li>
    </ul>

</body>

</html>
